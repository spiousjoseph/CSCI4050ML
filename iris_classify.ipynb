{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_classify.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spiousjoseph/CSCI4050ML/blob/master/iris_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKjoYxwf4TF5",
        "colab_type": "text"
      },
      "source": [
        "ID: 100555297\n",
        "\n",
        "Name: Sunu Pious Joseph\n",
        "\n",
        "CSCI4050\n",
        "\n",
        "ASSIGNMENT 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VhUDtRePLGg-",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hx4vs_JELYzq",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as pl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igj2H6SVMQfu"
      },
      "source": [
        "# Classification of flowers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EdAwS_f2Mnhl"
      },
      "source": [
        "## The Dataset: Iris classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aEoMdoS9MtGR",
        "colab": {}
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T6OCx563NXma"
      },
      "source": [
        "We have 150 samples which are the measurements of three different types of the _iris_ flower.\n",
        "\n",
        "Each sample consists of four measurements.  They correspond to the dimensions of (length and width) of different parts of the flower.\n",
        "\n",
        "The features are stored in a tensor `X` with shape (150, 4).\n",
        "\n",
        "Each sample also has an integer (0, 1, 2) that indicates the species of the sample: (0: setosa, 1: versicolor, 2: virginica).  We use one-hot encoding.  Namely, we have:\n",
        "\n",
        "$$\\begin{eqnarray}\n",
        "\\mathrm{enc}(0) &=& [1, 0, 0] \\\\\n",
        "\\mathrm{enc}(1) &=& [0, 1, 0] \\\\\n",
        "\\mathrm{enc}(2) &=& [0, 0, 1] \\\\\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_EtVTA3nMvrp",
        "colab": {}
      },
      "source": [
        "# ---------------------\n",
        "# Load the data\n",
        "# ---------------------\n",
        "n_samples = len(iris.data)\n",
        "n_species = len(iris.target_names)\n",
        "X = tf.constant(iris.data, dtype=tf.float64)\n",
        "\n",
        "I = iris.target\n",
        "Y = np.zeros((n_samples, n_species))\n",
        "Y[np.arange(n_samples), I] = 1\n",
        "Y = tf.constant(Y, dtype=tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XL2Y7r2o_TWC",
        "outputId": "37675a6e-553a-4121-c25a-fcc7f12d7859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# --------------------------\n",
        "# Inspect the data\n",
        "# --------------------------\n",
        "print(\"Features of first ten samples.\")\n",
        "print(X[:10, :])\n",
        "print()\n",
        "print(\"Species as one-hot vectors\")\n",
        "print(Y[:10, :])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features of first ten samples.\n",
            "tf.Tensor(\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]], shape=(10, 4), dtype=float64)\n",
            "\n",
            "Species as one-hot vectors\n",
            "tf.Tensor(\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]], shape=(10, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-IEHecA0MzNk"
      },
      "source": [
        "## Multi-class logistic regression.\n",
        "\n",
        "Consider the feature vector $x\\in\\mathbf{R}^4$ of a single sample.  You need to build a model that predicts the species as a probability distribution $p = [p_0, p_1, p_2] \\in\\mathbf{R}^3$.\n",
        "\n",
        "In order to build the model, we will need two _transformations_ applied to $x$.\n",
        "\n",
        "### Linear transformation\n",
        "---\n",
        "\n",
        "$$ z = W\\cdot x + b $$\n",
        "where $W\\sim (3, 4)$ and $b\\sim(1, 3)$\n",
        "\n",
        "The linear transformation produces a vector $z\\in\\mathbf{R}^3$.  This is known as the _logit_ vector.\n",
        "\n",
        "#### Batch processing\n",
        "When we have a batch of samples $X\\sim(150, 4)$, we can perform\n",
        "the linear transformation as:\n",
        "\n",
        "$$ Z = X\\cdot W^T + b $$\n",
        "where $Z\\sim (150, 3)$.\n",
        "\n",
        "### Softmax transformation\n",
        "---\n",
        "\n",
        "Next we will map the logit vector to a proper probability distribution.  This is done by taking the exponentiation of each $z_i$, and renormalize by the sum.\n",
        "\n",
        "$$ p_i = \\frac{\\exp(z_i)}{\\sum_{k=0}^2 \\exp(z_i)} $$\n",
        "\n",
        "This is known as the _softmax_ transformation:\n",
        "\n",
        "$$ p = \\mathrm{softmax}(z) $$\n",
        "\n",
        "### The final model\n",
        "---\n",
        "\n",
        "Together, we have the following model:\n",
        "\n",
        "$$ \\mathrm{model}(X|\\theta) = \\mathrm{softmax}\\left(X\\cdot W^T + b\\right) $$\n",
        "\n",
        "The model parameter $\\theta = (W, b)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RCPGOukZEKmc"
      },
      "source": [
        "_Hint_\n",
        "\n",
        "Tensorflow comes with a built-in softmax function:\n",
        "\n",
        "```python\n",
        "P = tf.nn.softmax(Z)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_6yiA2hKVqNK"
      },
      "source": [
        "**Implement the model function\n",
        "that accepts a batch of feature vectors, and\n",
        "returns the batch of probabilities.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jY6o_Iu-qgST",
        "colab": {}
      },
      "source": [
        "def model(X, theta):\n",
        "  # complete\n",
        "  w, b = theta\n",
        "  return tf.nn.softmax( tf.tensordot(X, tf.transpose(W0), 1) + b ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJkzWDTvG6ts",
        "colab": {}
      },
      "source": [
        "# -------------------------------------\n",
        "# Testing your model\n",
        "# -------------------------------------\n",
        "W0 = tf.Variable(np.random.randn(3, 4))\n",
        "b0 = tf.Variable(np.random.randn(1, 3))\n",
        "\n",
        "P = model(X, [W0, b0])\n",
        "\n",
        "\n",
        "assert(P.shape == (150,3))\n",
        "assert(np.all(0 <= P))\n",
        "assert(np.all(P <= 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_7O6loYGWcod"
      },
      "source": [
        "## The loss function\n",
        "\n",
        "Once a prediction probability, $p = [p_0, p_1, p_2]$, is made by the model, but the true output is given by $y = [y_0, y_1, y_2]$, where only one $y_i = 1$.\n",
        "\n",
        "We measure the accuracy of the prediction using _cross entropy_ between $y$ and $p$, as defined as:\n",
        "\n",
        "$$\\mathrm{crossentropy}(y, p) = - \\sum_{i=0}^2 y_i\\cdot\\log(p_i)$$\n",
        "\n",
        "When a batch of prediction probabilities $Y$, and true categories $Y_\\mathrm{true}$ is given, the loss can be the mean average of the cross entropy:\n",
        "\n",
        "$$ \\mathrm{loss}(Y^\\mathrm{true}, Y)=\\frac{1}{n}\\sum_{i=1}^n\n",
        "\\mathrm{crossentropy}(y^\\mathrm{true}_i, y_i)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcUKqI1_kllc"
      },
      "source": [
        "**Implement the loss function that accepts as input:**\n",
        "\n",
        "1. A batch of the true categories in one-hot encoding.\n",
        "2. A batch of prediction probabilities.\n",
        "\n",
        "The loss function is to return a **single** scalar tensor as the loss.\n",
        "\n",
        "*Hint*:\n",
        "\n",
        "Tensorflow comes with a built-in cross-entropy loss function:\n",
        "\n",
        "```python\n",
        "tf.losses.categorical_crossentropy(Y_true, Y_pred)\n",
        "```\n",
        "\n",
        "which returns a tensor of losses with shape `(150,)`.  You will need to further reduce this to a scalar tensor using:\n",
        "\n",
        "```python\n",
        "tf.reduce_mean(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FLr3aPlLlmfW",
        "colab": {}
      },
      "source": [
        "def loss(Y_true, Y_pred):\n",
        "  # complete\n",
        "  temp1 = tf.losses.categorical_crossentropy(Y_true, Y_pred)\n",
        "  temp2 = tf.reduce_mean(temp1)\n",
        "  return temp2\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FFlFWvlnTyBd",
        "colab": {}
      },
      "source": [
        "# --------------------------------\n",
        "# Test the loss function\n",
        "# --------------------------------\n",
        "\n",
        "assert(loss(Y, Y).shape == ())\n",
        "assert(loss(Y, Y).numpy() < 1E-5)\n",
        "\n",
        "assert(loss(Y, model(X, [W0, b0])) > 1E-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7bF7HM-PlpUI"
      },
      "source": [
        "## Training by optimization\n",
        "\n",
        "Recall the objective is to perform model parameter estimation to minimize the loss.  This is done with gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_fKC0DdJ8DMi"
      },
      "source": [
        "**Implement a generic _train_ function as follows.**\n",
        "\n",
        "**Input arguments**\n",
        "\n",
        "1. model: a model function\n",
        "2. theta: a list of tensorflow variables which will be the model parameters\n",
        "3. loss: a loss function\n",
        "4. X: a batch of inputs\n",
        "5. Y: a batch of true outputs\n",
        "6. epochs: the _total_ number of epochs to run\n",
        "7. alpha: the learning rate\n",
        "\n",
        "**Output**\n",
        "\n",
        "- A _numpy array_ of shapes `(epochs,)` which represents the loss _after_ each epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ttgZSthWHCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG2t3Xoa92t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize(model, loss, X, Y, theta, alpha=0.01):\n",
        "  with tf.GradientTape() as tape:\n",
        "    L = loss(Y, model(X, theta))\n",
        "  \n",
        "  grads = tape.gradient(L, theta)\n",
        "  \n",
        "  # update the variables in theta\n",
        "  for var, grad in zip(theta, grads):\n",
        "    var.assign_sub(alpha * grad)\n",
        "  \n",
        "  return loss(Y, model(X, theta))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jJi8v_wR6Lxq",
        "colab": {}
      },
      "source": [
        "def train(model, loss, X, Y, theta, alpha, epochs):\n",
        "  temp = []\n",
        "  for i in range(epochs):\n",
        "    L = optimize(model, loss, X, Y, theta)\n",
        "    if i % (epochs // 10) == 0:\n",
        "      print(\"[%d]: %.2f\" % (i, L))\n",
        "    temp.append(L)\n",
        "  return np.array(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uO1dRmyO-TBY"
      },
      "source": [
        "**Choose the epochs and learning rate accordingly**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UNVPmJoiVPq8",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "alpha = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3YziPtDzqL",
        "colab_type": "code",
        "outputId": "488f4545-1baa-415b-be7f-76003b1856c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "training_losses = train(model, loss, X, Y, [W0, b0], alpha, epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]: 7.97\n",
            "[100]: 0.54\n",
            "[200]: 0.49\n",
            "[300]: 0.46\n",
            "[400]: 0.43\n",
            "[500]: 0.41\n",
            "[600]: 0.39\n",
            "[700]: 0.38\n",
            "[800]: 0.36\n",
            "[900]: 0.35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WIaguavFWCvX",
        "colab": {}
      },
      "source": [
        "# ---------------------------\n",
        "# Testing training loss\n",
        "# ---------------------------\n",
        "\n",
        "assert(training_losses.shape == (epochs,))\n",
        "\n",
        "# Make sure the training loss is sufficient\n",
        "assert(training_losses[-1] < 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ARRxNdWJ6p_"
      },
      "source": [
        "# Accuracy\n",
        "\n",
        "To see how the model can predict the species, we will evaluate the accuracy as the percentage of _correct_ prediction.\n",
        "\n",
        "Suppose that we have a prediction `Y_pred` as probabilities of shape `(150,3)`.\n",
        "We can use the Numpy argmax to find the index with the greatest probability.\n",
        "\n",
        "```python\n",
        "I_pred = np.argmax(Y_pred, axis=1)\n",
        "```\n",
        "\n",
        "where `I_pred` has a shape of `(150,)`.  We can compute the percentage of _correct_ guesses by element comparison with `I_true` and then count the number of `1`s using `np.sum(...)`.\n",
        "\n",
        "```python\n",
        "total_correct = np.sum(I_true == I_pred)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I_lqT9yEQT_C"
      },
      "source": [
        "**Implement a function `evaluate` that will evaluate the accuracy of a model with respect to a given model parameter `theta`** . \n",
        "\n",
        "**Input parameters**\n",
        "\n",
        "1. model: a model to be evaluated\n",
        "2. theta: the model parameter to use\n",
        "3. X: a batch of input\n",
        "4. I_true: the true categories (as integers) for the batch of input\n",
        "\n",
        "**Output**\n",
        "\n",
        "- An float number between 0 and 1.0 which is the pecentage of _correct_ guesses by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0ekEBrjtOmIx",
        "colab": {}
      },
      "source": [
        "def evaluate(model, theta, X, I_true):\n",
        "  w, b = theta\n",
        "  Y_pred = model(X, [w, b])\n",
        "  I_pred = np.argmax(Y_pred, axis=1)\n",
        "  total_correct = np.sum(I_true == I_pred)\n",
        "  num = total_correct/150\n",
        "  return num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "94MaMKsGPKSx",
        "outputId": "74f30dec-8819-4a22-832a-8acc3f70ccf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# ----------------------------------\n",
        "# Test the accuracy\n",
        "# ----------------------------------\n",
        "\n",
        "W = tf.Variable(np.random.randn(3, 4))\n",
        "b = tf.Variable(np.random.randn(1, 3))\n",
        "accuracy = evaluate(model, [W, b], X, I)\n",
        "print(\"Accuracy: %.2f %%\" % (accuracy * 100))\n",
        "\n",
        "assert(accuracy.shape == ())\n",
        "assert(0.90 < accuracy <= 1.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 90.00 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-336-5e2fa303bbf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.90\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BKZS0vW2X79-",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}